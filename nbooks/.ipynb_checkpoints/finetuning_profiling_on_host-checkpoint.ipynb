{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning a Pretrained Network for Style Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to prepare the data. This involves the following parts:\n",
    "* Get the ImageNet ilsvrc pretrained model with the provided shell scripts.\n",
    "* Download a subset of the overall Flickr style dataset for this demo.\n",
    "* Compile the downloaded Flickr dataset into a database that Caffe can then consume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls ../../caffe/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "caffe_root = '../../caffe/'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "assert os.path.exists(caffe_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "import caffe\n",
    "import time\n",
    "\n",
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "%matplotlib inline\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper function for deprocessing preprocessed images, e.g., for display.\n",
    "def deprocess_net_image(image):\n",
    "    image = image.copy()              # don't modify destructively\n",
    "    image = image[::-1]               # BGR -> RGB\n",
    "    image = image.transpose(1, 2, 0)  # CHW -> HWC\n",
    "    image += [123, 117, 104]          # (approximately) undo mean subtraction\n",
    "\n",
    "    # clamp values in [0, 255]\n",
    "    image[image < 0], image[image > 255] = 0, 255\n",
    "\n",
    "    # round and cast from float32 to uint8\n",
    "    image = np.round(image)\n",
    "    image = np.require(image, dtype=np.uint8)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and dataset download\n",
    "\n",
    "Download data required for this exercise.\n",
    "\n",
    "- `get_ilsvrc_aux.sh` to download the ImageNet data mean, labels, etc.\n",
    "- `download_model_binary.py` to download the pretrained reference model\n",
    "- `finetune_flickr_style/assemble_data.py` downloadsd the style training and testing data\n",
    "\n",
    "We'll download just a small subset of the full dataset for this exercise: just 2000 of the 80K images, from 5 of the 20 style categories.  (To download the full dataset, set `full_dataset = True` in the cell below.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download just a small subset of the data for this exercise.\n",
    "# (2000 of 80K images, 5 of 20 labels.)\n",
    "# To download the entire dataset, set `full_dataset = True`.\n",
    "full_dataset = False\n",
    "if full_dataset:\n",
    "    NUM_STYLE_IMAGES = NUM_STYLE_LABELS = -1\n",
    "else:\n",
    "    NUM_STYLE_IMAGES = 2000\n",
    "    NUM_STYLE_LABELS = 5\n",
    "\n",
    "# This downloads the ilsvrc auxiliary data (mean file, etc),\n",
    "# and a subset of 2000 images for the style recognition task.\n",
    "\n",
    "import os\n",
    "os.chdir(caffe_root)  # run scripts from caffe root\n",
    "\n",
    "if (not os.path.exists('data/ilsvrc12/synset_words.txt')) or \\\n",
    "   (not os.path.exists('examples/finetune_flickr_style/style_names.txt')):\n",
    "\n",
    "    !data/ilsvrc12/get_ilsvrc_aux.sh\n",
    "    !scripts/download_model_binary.py models/bvlc_reference_caffenet\n",
    "    !python examples/finetune_flickr_style/assemble_data.py \\\n",
    "        --workers=-1  --seed=1701 \\\n",
    "        --images=$NUM_STYLE_IMAGES  --label=$NUM_STYLE_LABELS\n",
    "else:\n",
    "    print('models and meta data exist')\n",
    "# move to example directory \n",
    "os.chdir('examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "weights = caffe_root + 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'\n",
    "assert os.path.exists(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the 1000 ImageNet labels from `ilsvrc12/synset_words.txt`, and the 5 style labels from `finetune_flickr_style/style_names.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load ImageNet labels to imagenet_labels\n",
    "imagenet_label_file = caffe_root + 'data/ilsvrc12/synset_words.txt'\n",
    "imagenet_labels = list(np.loadtxt(imagenet_label_file, str, delimiter='\\t'))\n",
    "assert len(imagenet_labels) == 1000\n",
    "print 'Loaded ImageNet labels:\\n', '\\n'.join(imagenet_labels[:10] + ['...'])\n",
    "\n",
    "# Load style labels to style_labels\n",
    "style_label_file = caffe_root + 'examples/finetune_flickr_style/style_names.txt'\n",
    "style_labels = list(np.loadtxt(style_label_file, str, delimiter='\\n'))\n",
    "if NUM_STYLE_LABELS > 0:\n",
    "    style_labels = style_labels[:NUM_STYLE_LABELS]\n",
    "print '\\nLoaded style labels:\\n', ', '.join(style_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  Defining and running the nets\n",
    "\n",
    "We'll start by defining `caffenet`, a function which initializes the *CaffeNet* architecture (a minor variant on *AlexNet*), taking arguments specifying the data and number of output classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from caffe import layers as L\n",
    "from caffe import params as P\n",
    "\n",
    "weight_param = dict(lr_mult=1, decay_mult=1)\n",
    "bias_param   = dict(lr_mult=2, decay_mult=0)\n",
    "learned_param = [weight_param, bias_param]\n",
    "\n",
    "frozen_param = [dict(lr_mult=0)] * 2\n",
    "\n",
    "def conv_relu(bottom, ks, nout, stride=1, pad=0, group=1,\n",
    "              param=learned_param,\n",
    "              weight_filler=dict(type='gaussian', std=0.01),\n",
    "              bias_filler=dict(type='constant', value=0.1)):\n",
    "    conv = L.Convolution(bottom, kernel_size=ks, stride=stride,\n",
    "                         num_output=nout, pad=pad, group=group,\n",
    "                         param=param, weight_filler=weight_filler,\n",
    "                         bias_filler=bias_filler)\n",
    "    return conv, L.ReLU(conv, in_place=True)\n",
    "\n",
    "def fc_relu(bottom, nout, param=learned_param,\n",
    "            weight_filler=dict(type='gaussian', std=0.005),\n",
    "            bias_filler=dict(type='constant', value=0.1)):\n",
    "    fc = L.InnerProduct(bottom, num_output=nout, param=param,\n",
    "                        weight_filler=weight_filler,\n",
    "                        bias_filler=bias_filler)\n",
    "    return fc, L.ReLU(fc, in_place=True)\n",
    "\n",
    "def max_pool(bottom, ks, stride=1):\n",
    "    return L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)\n",
    "\n",
    "def caffenet(data, label=None, train=True, num_classes=1000,\n",
    "             classifier_name='fc8', learn_all=False):\n",
    "    \"\"\"Returns a NetSpec specifying CaffeNet, following the original proto text\n",
    "       specification (./models/bvlc_reference_caffenet/train_val.prototxt).\"\"\"\n",
    "    n = caffe.NetSpec()\n",
    "    n.data = data\n",
    "    param = learned_param if learn_all else frozen_param\n",
    "    n.conv1, n.relu1 = conv_relu(n.data, 11, 96, stride=4, param=param)\n",
    "    n.pool1 = max_pool(n.relu1, 3, stride=2)\n",
    "    n.norm1 = L.LRN(n.pool1, local_size=5, alpha=1e-4, beta=0.75)\n",
    "    n.conv2, n.relu2 = conv_relu(n.norm1, 5, 256, pad=2, group=2, param=param)\n",
    "    n.pool2 = max_pool(n.relu2, 3, stride=2)\n",
    "    n.norm2 = L.LRN(n.pool2, local_size=5, alpha=1e-4, beta=0.75)\n",
    "    n.conv3, n.relu3 = conv_relu(n.norm2, 3, 384, pad=1, param=param)\n",
    "    n.conv4, n.relu4 = conv_relu(n.relu3, 3, 384, pad=1, group=2, param=param)\n",
    "    n.conv5, n.relu5 = conv_relu(n.relu4, 3, 256, pad=1, group=2, param=param)\n",
    "    n.pool5 = max_pool(n.relu5, 3, stride=2)\n",
    "    n.fc6, n.relu6 = fc_relu(n.pool5, 4096, param=param)\n",
    "    if train:\n",
    "        n.drop6 = fc7input = L.Dropout(n.relu6, in_place=True)\n",
    "    else:\n",
    "        fc7input = n.relu6\n",
    "    n.fc7, n.relu7 = fc_relu(fc7input, 4096, param=param)\n",
    "    if train:\n",
    "        n.drop7 = fc8input = L.Dropout(n.relu7, in_place=True)\n",
    "    else:\n",
    "        fc8input = n.relu7\n",
    "    # always learn fc8 (param=learned_param)\n",
    "    fc8 = L.InnerProduct(fc8input, num_output=num_classes, param=learned_param)\n",
    "    # give fc8 the name specified by argument `classifier_name`\n",
    "    n.__setattr__(classifier_name, fc8)\n",
    "    if not train:\n",
    "        n.probs = L.Softmax(fc8)\n",
    "    if label is not None:\n",
    "        n.label = label\n",
    "        n.loss = L.SoftmaxWithLoss(fc8, n.label)\n",
    "        n.acc = L.Accuracy(fc8, n.label)\n",
    "    # write the net to a temporary file and return its filename\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "        f.write(str(n.to_proto()))\n",
    "        return f.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function `style_net` which calls `caffenet` on data from the Flickr style dataset.\n",
    "\n",
    "The new network will also have the *CaffeNet* architecture, with differences in the input and output:\n",
    "\n",
    "- the input is the Flickr style data we downloaded, provided by an `ImageData` layer\n",
    "- the output is a distribution over 20 classes rather than the original 1000 ImageNet classes\n",
    "- the classification layer is renamed from `fc8` to `fc8_flickr` to tell Caffe not to load the original classifier (`fc8`) weights from the ImageNet-pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def style_net(train=True, learn_all=False, subset=None):\n",
    "    if subset is None:\n",
    "        subset = 'train' if train else 'test'\n",
    "    source = caffe_root + 'data/flickr_style/%s.txt' % subset\n",
    "    transform_param = dict(mirror=train, crop_size=227,\n",
    "        mean_file=caffe_root + 'data/ilsvrc12/imagenet_mean.binaryproto')\n",
    "    style_data, style_label = L.ImageData(\n",
    "        transform_param=transform_param, source=source,\n",
    "        batch_size=50, new_height=256, new_width=256, ntop=2)\n",
    "    return caffenet(data=style_data, label=style_label, train=train,\n",
    "                    num_classes=NUM_STYLE_LABELS,\n",
    "                    classifier_name='fc8_flickr',\n",
    "                    learn_all=learn_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def disp_preds(net, image, labels, k=5, name='ImageNet'):\n",
    "    input_blob = net.blobs['data']\n",
    "    net.blobs['data'].data[0, ...] = image\n",
    "    probs = net.forward(start='conv1')['probs'][0]\n",
    "    top_k = (-probs).argsort()[:k]\n",
    "    print 'top %d predicted %s labels =' % (k, name)\n",
    "    print '\\n'.join('\\t(%d) %5.2f%% %s' % (i+1, 100*probs[p], labels[p])\n",
    "                    for i, p in enumerate(top_k))\n",
    "\n",
    "def disp_imagenet_preds(net, image):\n",
    "    disp_preds(net, image, imagenet_labels, name='ImageNet')\n",
    "\n",
    "def disp_style_preds(net, image):\n",
    "    disp_preds(net, image, style_labels, name='style')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training the style classifier\n",
    "\n",
    "Now, we'll define a function `solver` to create our Caffe solvers, which are used to train the network (learn its weights).  In this function we'll set values for various parameters used for learning, display, and \"snapshotting\" -- see the inline comments for explanations of what they mean.  You may want to play with some of the learning parameters to see if you can improve on the results here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from caffe.proto import caffe_pb2\n",
    "\n",
    "def solver(train_net_path, test_net_path=None, base_lr=0.001):\n",
    "    s = caffe_pb2.SolverParameter()\n",
    "\n",
    "    # Specify locations of the train and (maybe) test networks.\n",
    "    s.train_net = train_net_path\n",
    "    if test_net_path is not None:\n",
    "        s.test_net.append(test_net_path)\n",
    "        s.test_interval = 1000  # Test after every 1000 training iterations.\n",
    "        s.test_iter.append(100) # Test on 100 batches each time we test.\n",
    "\n",
    "    # The number of iterations over which to average the gradient.\n",
    "    # Effectively boosts the training batch size by the given factor, without\n",
    "    # affecting memory utilization.\n",
    "    s.iter_size = 1\n",
    "    \n",
    "    s.max_iter = 100000     # # of times to update the net (training iterations)\n",
    "    \n",
    "    # Solve using the stochastic gradient descent (SGD) algorithm.\n",
    "    # Other choices include 'Adam' and 'RMSProp'.\n",
    "    s.type = 'SGD'\n",
    "\n",
    "    # Set the initial learning rate for SGD.\n",
    "    s.base_lr = base_lr\n",
    "\n",
    "    # Set `lr_policy` to define how the learning rate changes during training.\n",
    "    # Here, we 'step' the learning rate by multiplying it by a factor `gamma`\n",
    "    # every `stepsize` iterations.\n",
    "    s.lr_policy = 'step'\n",
    "    s.gamma = 0.1\n",
    "    s.stepsize = 20000\n",
    "\n",
    "    # Set other SGD hyperparameters. Setting a non-zero `momentum` takes a\n",
    "    # weighted average of the current gradient and previous gradients to make\n",
    "    # learning more stable. L2 weight decay regularizes learning, to help prevent\n",
    "    # the model from overfitting.\n",
    "    s.momentum = 0.9\n",
    "    s.weight_decay = 5e-4\n",
    "\n",
    "    # Display the current training loss and accuracy every 1000 iterations.\n",
    "    s.display = 1000\n",
    "\n",
    "    # Snapshots are files used to store networks we've trained.  Here, we'll\n",
    "    # snapshot every 10K iterations -- ten times during training.\n",
    "    s.snapshot = 10000\n",
    "    s.snapshot_prefix = caffe_root + 'models/finetune_flickr_style/finetune_flickr_style'\n",
    "    \n",
    "    # Train on the GPU.  Using the CPU to train large networks is very slow.\n",
    "    s.solver_mode = caffe_pb2.SolverParameter.GPU\n",
    "    \n",
    "    # Write the solver to a temporary file and return its filename.\n",
    "    with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "        f.write(str(s))\n",
    "        return f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_solvers(niter, solvers, disp_interval=100):\n",
    "    \"\"\"Run solvers for niter iterations,\n",
    "       returning the loss and accuracy recorded each iteration.\n",
    "       `solvers` is a list of (name, solver) tuples.\"\"\"\n",
    "    blobs = ('loss', 'acc')\n",
    "    loss, acc = ({name: np.zeros(niter) for name, _ in solvers}\n",
    "                 for _ in blobs)\n",
    "    for it in range(niter):\n",
    "        for name, s in solvers:\n",
    "            s.step(1)  # run a single SGD step in Caffe\n",
    "            loss[name][it], acc[name][it] = (s.net.blobs[b].data.copy()\n",
    "                                             for b in blobs)\n",
    "        if it % disp_interval == 0 or it + 1 == niter:\n",
    "            loss_disp = '; '.join('%s: loss=%.3f, acc=%2d%%' %\n",
    "                                  (n, loss[n][it], np.round(100*acc[n][it]))\n",
    "                                  for n, _ in solvers)\n",
    "            print '%3d) %s' % (it, loss_disp)     \n",
    "    # Save the learned weights from both nets.\n",
    "    weight_dir = tempfile.mkdtemp()\n",
    "    weights = {}\n",
    "    for name, s in solvers:\n",
    "        filename = 'weights.%s.caffemodel' % name\n",
    "        weights[name] = os.path.join(weight_dir, filename)\n",
    "        s.net.save(weights[name])\n",
    "    return loss, acc, weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create and run solvers to train nets for the style recognition task.  We'll create two solvers -- one (`style_solver`) will have its train net initialized to the ImageNet-pretrained weights (this is done by the call to the `copy_from` method), and the other (`scratch_style_solver`) will start from a *randomly* initialized net.\n",
    "\n",
    "During training, we should see that the ImageNet pretrained net is learning faster and attaining better accuracies than the scratch net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "niter = 500  # number of iterations to train\n",
    "\n",
    "# Reset style_solver as before.\n",
    "style_solver_filename = solver(style_net(train=True))\n",
    "style_solver = caffe.get_solver(style_solver_filename)\n",
    "style_solver.net.copy_from(weights)\n",
    "\n",
    "# For reference, we also create a solver that isn't initialized from\n",
    "# the pretrained ImageNet weights.\n",
    "scratch_style_solver_filename = solver(style_net(train=True))\n",
    "scratch_style_solver = caffe.get_solver(scratch_style_solver_filename)\n",
    "\n",
    "print 'solvers for %d iterations...' % niter\n",
    "solvers = [('pretrained', style_solver),\n",
    "           ('scratch', scratch_style_solver)]\n",
    "\n",
    "loss, acc, weights = run_solvers(niter, solvers)\n",
    "\n",
    "print 'Done.'\n",
    "\n",
    "train_loss, scratch_train_loss = loss['pretrained'], loss['scratch']\n",
    "train_acc, scratch_train_acc = acc['pretrained'], acc['scratch']\n",
    "style_weights, scratch_style_weights = weights['pretrained'], weights['scratch']\n",
    "\n",
    "# Delete solvers to save memory.\n",
    "del style_solver, scratch_style_solver, solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the training loss and accuracy produced by the two training procedures.  Notice how quickly the ImageNet pretrained model's loss value (blue) drops, and that the randomly initialized model's loss value (green) barely (if at all) improves from training only the classifier layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(np.vstack([train_loss, scratch_train_loss]).T)\n",
    "xlabel('Iteration #')\n",
    "ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(np.vstack([train_acc, scratch_train_acc]).T)\n",
    "xlabel('Iteration #')\n",
    "ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_style_net(weights, test_iters=10):\n",
    "    test_net = caffe.Net(style_net(train=False), weights, caffe.TEST)\n",
    "    accuracy = 0\n",
    "    for it in xrange(test_iters):\n",
    "        accuracy += test_net.forward()['acc']\n",
    "    accuracy /= test_iters\n",
    "    return test_net, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_net, accuracy = eval_style_net(style_weights, test_iters=100)\n",
    "print 'Accuracy, trained from ImageNet initialization: %3.1f%%' % (100*accuracy, )\n",
    "scratch_test_net, scratch_accuracy = eval_style_net(scratch_style_weights)\n",
    "print 'Accuracy, trained from   random initialization: %3.1f%%' % (100*scratch_accuracy, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# training\n",
    "%timeit run_solvers(niter, solvers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# testing\n",
    "%timeit eval_style_net(style_weights, test_iters=100)"
   ]
  }
 ],
 "metadata": {
  "description": "Fine-tune the ImageNet-trained CaffeNet on new data.",
  "example_name": "Fine-tuning for Style Recognition",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "priority": 3
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
